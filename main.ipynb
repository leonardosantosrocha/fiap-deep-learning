{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instala os módulos necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install duckdb\n",
    "%pip install keras\n",
    "%pip install nbformat\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install matplotlib\n",
    "%pip install pydot\n",
    "%pip install scikit-learn\n",
    "%pip install seaborn\n",
    "%pip install tensorflow\n",
    "%pip install warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importa os módulos necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, SimpleRNN\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import duckdb as ddb\n",
    "import nbformat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ignora warnings que serão gerados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análise exploratória, feature engineering, treinamento e avaliação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_bbas3 = pd.read_csv(\"_datasets/bbas3/treino.csv\", usecols=range(2,20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao importar o conjunto de dados, notamos que a primeira coluna equivalia ao índice da linha, portanto, utilizamos o parâmetro \"usecols\" do método \"read_csv\" para removê-la, podendo assim, ler apenas os dados de treinamento necessários para construção do classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_bbas3.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_bbas3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conforme apresentado acima, notamos que nenhuma das variáveis apresenta valores nulos, portanto, neste momento, não precisaremos remover ou realizar a inputação de valores como tratamento a valores ausentes. \n",
    "\n",
    "Dessa forma, como próximos passos, iremos analisar o comportamento das variáveis, a fim de entender se o conjunto de dados é balanceado (número de compras e vendas similar) e, em seguida, verificar a correlação entre as variáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_distribution = ddb.sql(\"\"\"SELECT Label, COUNT(*) AS Regs from raw_bbas3 GROUP BY 1\"\"\").to_df()\n",
    "size = raw_bbas3.shape[0]\n",
    "buy_count = label_distribution[\"Regs\"][0]\n",
    "sell_count = label_distribution[\"Regs\"][1]\n",
    "buy_percentual = round((buy_count / size) * 100, 2)\n",
    "sell_percentual = round((sell_count / size) * 100, 2)\n",
    "\n",
    "print(f\"O conjunto de dados possui {size} registros, onde:\")\n",
    "print(f\" -> {buy_count} ou {buy_percentual}% são vendas\")\n",
    "print(f\" -> {sell_count} ou {sell_percentual}% são compras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O conjunto de dados apresenta uma boa distribuição entre as classes, sendo assim, não será necessário aplicar nenhuma técnica de amostragem para balancear os dados, o geralmente é feito para evitar que o modelo tornesse especialista em uma única classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = raw_bbas3.select_dtypes(\"number\").corr()\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "sns.heatmap(\n",
    "    correlation, \n",
    "    annot=True, \n",
    "    annot_kws={\"size\" : 10},\n",
    "    cmap=\"coolwarm\",\n",
    "    cbar=True,\n",
    "    linewidths=0.5,\n",
    "    linecolor=\"white\"\n",
    ")\n",
    "\n",
    "plt.title(\"\\nCorrelação entre as variáveis\\n\", fontdict={\"size\" : 12})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse momento, há dois comportamentos importantes a serem notados:\n",
    "\n",
    "- Variável dependente: a correlação entre a ação de venda/compra diminui ao passar dos dias, ou seja, considerando APENAS o que é apresentado acima, poderíamos pressupor que a ação é tomada com base nos dados mais recentes, ou seja, uma janela mais curta de dias.\n",
    "\n",
    "- Variáveis independentes: diferente da variável dependente, todas as variáveis independentes apresentam uma alta correlação entre sí, o que nos leva a pensar que o valor de fechamento em D-15 influencia em D-14 e assim sucessivamente.\n",
    "\n",
    "Dito isso, como bons cientistas de dados, começaremos a realizar os experimentos!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
